import pandas as pd
import os
from sklearn.model_selection import train_test_split

# --- Import Custom Utilities ---
try:
    from utils import preprocessing
    from utils import model_helpers
except ImportError:
    print("FATAL ERROR: Could not import from 'utils' directory.")
    print("Please ensure 'utils/__init__.py', 'utils/preprocessing.py', and 'utils/model_helpers.py' exist in the same directory.")
    exit()

# --- Define Global Paths ---
# Use relative paths so the script is portable
RAW_DATA_PATH = os.path.join('data', 'listings.csv')
CLEANED_DATA_PATH = os.path.join('data', 'listings_cleaned.csv')
# Note: Visuals are generated by notebooks, not this script.

def main():
    """
    Main function to run the entire analysis pipeline.
    """
    print("--- RUNNING MAIN PROJECT PIPELINE (TASKS 1-4) ---")
    
    # --- Task 1: Preprocessing ---
    print("\n--- STARTING TASK 1: DATA PREPROCESSING ---")
    
    # This function loads raw, cleans, engineers features, handles outliers,
    # runs the robust hotfix, and saves the cleaned file.
    # It also returns the cleaned DataFrame and the medians for the hotfix.
    df_clean, train_medians = preprocessing.run_full_preprocessing(
        RAW_DATA_PATH, CLEANED_DATA_PATH
    )
    
    if df_clean is None:
        print("Failed to load or process data. Exiting.")
        return

    print("--- TASK 1 COMPLETE ---")

    # --- Task 2: Regression Analysis ---
    print("\n--- STARTING TASK 2: REGRESSION ANALYSIS ---")
    
    # 1. Define X and y for regression
    y_reg = df_clean['log_price']
    num_features_reg, cat_features_reg = model_helpers.get_regression_features()
    
    # Filter features that exist
    num_features_reg = [col for col in num_features_reg if col in df_clean.columns]
    cat_features_reg = [col for col in cat_features_reg if col in df_clean.columns]
    
    # We must use the 'df_clean' DataFrame, which is guaranteed to be clean
    X_reg = df_clean[num_features_reg + cat_features_reg]
    
    # 2. Split data
    X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(
        X_reg, y_reg, test_size=0.2, random_state=42
    )
    
    # 3. Create preprocessor (sparse=True is fine for regression)
    preprocessor_reg = model_helpers.create_preprocessor(
        num_features_reg, cat_features_reg, sparse_output=True
    )
    
    # 4. Run comparison
    reg_results_df = model_helpers.run_regression_comparison(
        X_reg_train, y_reg_train, X_reg_test, y_reg_test, preprocessor_reg
    )
    
    print("\n--- Regression Results (Sorted by RMSE) ---")
    print(reg_results_df.to_string(float_format="%.4f"))
    print(f"\nBest Regression Model: {reg_results_df.iloc[0].name}")
    print("--- TASK 2 COMPLETE ---")

    # --- Task 3 & 4: Classification Analysis ---
    print("\n--- STARTING TASKS 3 & 4: CLASSIFICATION ANALYSIS ---")
    
    # 1. Define X and y
    y_class = df_clean['host_is_superhost'].astype(int)
    num_features_class, cat_features_class = model_helpers.get_classification_features()
    
    num_features_class = [col for col in num_features_class if col in df_clean.columns]
    cat_features_class = [col for col in cat_features_class if col in df_clean.columns]
    
    X_class = df_clean[num_features_class + cat_features_class]
    
    # 2. Split data (STRATIFIED)
    X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(
        X_class, y_class, test_size=0.2, random_state=42, stratify=y_class
    )
    
    # 3. Create preprocessor (sparse=False is CRITICAL for GaussianNB)
    preprocessor_class = model_helpers.create_preprocessor(
        num_features_class, cat_features_class, sparse_output=False  # <-- THIS IS THE FIX
    )
    
    # 4. Run comparison
    class_results_df, _ = model_helpers.run_classification_comparison(
        X_class_train, y_class_train, X_class_test, y_class_test, preprocessor_class
    )
    
    print("\n--- Classification Results (Sorted by F1-Score for Superhost) ---")
    print(class_results_df.to_string(float_format="%.4f"))
    print(f"\nBest Classification Model: {class_results_df.iloc[0].name}")
    print("--- TASKS 3 & 4 COMPLETE ---")

    print("\n--- MAIN PROJECT PIPELINE FINISHED ---")

if __name__ == "__main__":
    # Ensure NLTK data is downloaded before running preprocessing
    preprocessing.download_nltk_data()
    main()